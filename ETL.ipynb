{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c33fc6",
   "metadata": {},
   "source": [
    "# **Pipeline Design**\n",
    "1. Extract the data from CSV and JSON files to pandas\n",
    "2. Transform the data\n",
    "3. Split the JSON into two tables, one of the tables holding orders, the other\n",
    "holding order_items.\n",
    "4. Create database and load the cleaned data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082aeb7",
   "metadata": {},
   "source": [
    "## 1. Extract the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3c5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sqlalchemy\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edb5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get my database environment variables\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "# postgres db connection string\n",
    "DB_CONNECTION_STRING = f\"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}\" \n",
    "\n",
    "# Configure Base Path for Data Files to ensure readability and prevent DRY issues\n",
    "BASE_PATH = \"/Users/mac/Documents/Prosper_Python/ETL_Design\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee8d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for extraction\n",
    "\n",
    "def extract():\n",
    "    \"\"\"\n",
    "    Extract data from the data sources (CSV & JSON) and return as dictionary tuples,\n",
    "    using the Try, except method. And if the file is not found, return an empty DataFrame.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def safe_read_csv(filename):\n",
    "            path = os.path.join(BASE_PATH, filename)\n",
    "            return pd.read_csv(path) if os.path.exists(path) else pd.DataFrame()\n",
    "        df_employees = safe_read_csv(\"employees.csv\")\n",
    "        df_customers = safe_read_csv(\"customers.csv\")\n",
    "        df_products = safe_read_csv(\"products.csv\")\n",
    "        df_stores = safe_read_csv(\"stores.csv\")\n",
    "       \n",
    "       # Read JSON file\n",
    "        json_path = os.path.join(BASE_PATH, \"orders.json\")\n",
    "        orders_data = []\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, \"r\") as f:\n",
    "                orders_data = json.load(f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    return df_employees.to_dict(), df_customers.to_dict(), df_products.to_dict(), df_stores.to_dict(), orders_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef620c2",
   "metadata": {},
   "source": [
    "## 2. Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4219be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the help function to ensure the email address and phone number are valid as required in the problem statement.\n",
    "def is_valid_email(email):\n",
    "    \"\"\"Returns True if email follows a valid format, else False.\"\"\"\n",
    "    pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "    return bool(re.match(pattern, email))\n",
    "\n",
    "def is_valid_phone(phone):\n",
    "    \"\"\"Returns True if phone follows a valid format (e.g., +1234567890), else False.\"\"\"\n",
    "    pattern = r\"^\\+?\\d{10,15}$\"\n",
    "    return bool(re.match(pattern, phone))\n",
    "\n",
    "#create a function to transform the data\n",
    "def transform(df_employees_dict, df_customers_dict, df_products_dict, df_stores_dict, orders_data):\n",
    "    \"\"\"\n",
    "    Transform the extracted data into a structured format suitable for loading into a database.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert dictionaries to DataFrames\n",
    "    df_employees = pd.DataFrame(df_employees_dict)\n",
    "    df_customers = pd.DataFrame(df_customers_dict)\n",
    "    df_products = pd.DataFrame(df_products_dict)\n",
    "    df_stores = pd.DataFrame(df_stores_dict)\n",
    "\n",
    "    #1. Handle missing data by filling NaN with 'unknown' for text fields\n",
    "    for df in [df_employees, df_customers, df_products, df_stores]:\n",
    "        str_cols = df.select_dtypes(include='object').columns\n",
    "        df[str_cols] = df[str_cols].fillna(\"unknown\")\n",
    "  \n",
    "    # 2. Handle Duplicates\n",
    "    df_employees.drop_duplicates(inplace=True)\n",
    "    df_customers.drop_duplicates(inplace=True)\n",
    "    df_products.drop_duplicates(inplace=True)\n",
    "    df_stores.drop_duplicates(inplace=True)\n",
    "\n",
    "    #3. Merging first name and last name column to form full name,\n",
    "    df_employees[\"Full_Name\"] = df_employees[\"First_Name\"].fillna(\"\") + \" \" + df_employees[\"Last_Name\"].fillna(\"\")\n",
    "    df_customers[\"Full_Name\"] = df_customers[\"First_Name\"].fillna(\"\") + \" \" + df_customers[\"Last_Name\"].fillna(\"\")\n",
    "\n",
    "    #4. Drop original first and last name columns\n",
    "    for df in [df_employees, df_customers]:\n",
    "        for col in [\"First_Name\", \"Last_Name\"]:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=col, inplace=True)\n",
    "\n",
    "     #5. Adding required columns (email and phone number column to the employee and customer table, if not present and fill the value accordingly)\n",
    "    required_columns = {\n",
    "        \"employees\" : [\"Email\", \"Phone\"],\n",
    "        \"customers\" : [\"Email\", \"Phone\"]\n",
    "    }\n",
    "    for df_name, cols in required_columns.items():\n",
    "        df = df_employees if df_name == \"employees\" else df_customers\n",
    "        for col in cols:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None # Add the column with None values if it doesn't exist\n",
    "\n",
    "    #6. Validate email and phone numbers\n",
    "    df_employees[\"Email\"] = df_employees[\"Email\"].apply(lambda x: x if is_valid_email(str(x)) else \"unknown\")\n",
    "    df_employees[\"Phone\"] = df_employees[\"Phone\"].apply(lambda x: x if is_valid_phone(str(x)) else \"unknown\")\n",
    "    df_customers[\"Email\"] = df_customers[\"Email\"].apply(lambda x: x if is_valid_email(str(x)) else \"unknown\")\n",
    "    df_customers[\"Phone\"] = df_customers[\"Phone\"].apply(lambda x: x if is_valid_phone(str(x)) else \"unknown\")\n",
    "\n",
    "\n",
    "    \n",
    "    #7. Split orders into two tables, one of the tables holding orders, the other holding order_items.\n",
    "    # create an empty list to hold order items\n",
    "    orders_list = []\n",
    "    order_items_list = []\n",
    "\n",
    "    for order in orders_data: \n",
    "        orders_list.append([\n",
    "            order[\"Order_ID\"], order[\"Customer_ID\"],\n",
    "            order[\"Store_ID\"], order[\"Order_Date\"], order[\"Total_Amount\"]\n",
    "        ])\n",
    "        for item in order[\"Items\"]:\n",
    "            order_items_list.append([\n",
    "                order[\"Order_ID\"], item[\"Product_ID\"], item[\"Quantity\"], item[\"Unit_Price\"]\n",
    "            ])\n",
    "\n",
    "\n",
    "    # Convert lists to DataFrames\n",
    "    df_orders = pd.DataFrame(orders_list, columns=[\"Order_ID\", \"Customer_ID\", \"Store_ID\", \"Order_Date\", \"Total_Amount\"])\n",
    "    df_order_items = pd.DataFrame(order_items_list, columns=[\"Order_ID\", \"Product_ID\", \"Quantity\", \"Unit_Price\"])\n",
    "\n",
    "    return df_employees, df_customers, df_products, df_stores, df_orders, df_order_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44502abd",
   "metadata": {},
   "source": [
    "## 3. Load to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de8e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database engine\n",
    "def load_to_db(df_employees, df_customers, df_products, df_stores, df_orders, df_order_items):\n",
    "    \"\"\"\n",
    "    Load the transformed data into the PostgreSQL database.\n",
    "    \"\"\"\n",
    "    engine = create_engine(DB_CONNECTION_STRING)\n",
    "\n",
    "    try:\n",
    "        df_employees.to_sql('employees', engine, if_exists='append', index=False)\n",
    "        df_customers.to_sql('customers', engine, if_exists='append', index=False)\n",
    "        df_products.to_sql('products', engine, if_exists='append', index=False)\n",
    "        df_stores.to_sql('stores', engine, if_exists='append', index=False)\n",
    "        df_orders.to_sql('orders', engine, if_exists='append', index=False)\n",
    "        df_order_items.to_sql('order_items', engine, if_exists='append', index=False)\n",
    "        print(\"Data loaded successfully into the database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data to database: {e}\")\n",
    "    finally:\n",
    "        engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c24e977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into the database.\n"
     ]
    }
   ],
   "source": [
    "# Using the Functions\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the ETL process.\n",
    "    \"\"\"\n",
    "    df_employees_dict, df_customers_dict, df_products_dict, df_stores_dict, orders_data = extract()\n",
    "    if all([df_employees_dict, df_customers_dict, df_products_dict, df_stores_dict, orders_data]):\n",
    "        df_employees, df_customers, df_products, df_stores, df_orders, df_order_items = transform(\n",
    "            df_employees_dict, df_customers_dict, df_products_dict, df_stores_dict, orders_data\n",
    "        )\n",
    "        load_to_db(df_employees, df_customers, df_products, df_stores, df_orders, df_order_items)\n",
    "    else:\n",
    "        print(\"No data extracted. ETL process terminated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
